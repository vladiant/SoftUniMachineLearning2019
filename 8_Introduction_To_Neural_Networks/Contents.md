# Introduction to Neural Networks

* Problem statement, motivation and results. Pros and cons
* NN representation
* Perceptron, softmax function
* Two-class and multi-class problems
* Feed-forward NNs: forward propagation
* Chain rule. Backpropagation and learning
* Regularization. Cross-entropy cost function
* NN examples with real data
* Convolutional NNs: ideas, example

## Links
* [Youtube List: 10: Neural Networks - The Nature of Code](https://www.youtube.com/playlist?list=PLRqwX-V7Uu6aCibgK1PTWWu9by6XFdCfh)
* [Test Run - Neural Network Back-Propagation for Programmers](https://docs.microsoft.com/en-us/archive/msdn-magazine/2012/october/test-run-neural-network-back-propagation-for-programmers)
* [sacridini/OpenNeuralNetwork](https://github.com/sacridini/OpenNeuralNetwork)
* [Artificial Neural Networks implemented in C++](https://github.com/ralampay/ann)
* [8 Inspirational Applications of Deep Learning](https://machinelearningmastery.com/inspirational-applications-deep-learning/)
* [The Dark Secret at the Heart of AI](https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/)
* [Backpropagation](https://ml-cheatsheet.readthedocs.io/en/latest/backpropagation.html)
* [Varying regularization in Multi-layer Perceptron](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_alpha.html#sphx-glr-auto-examples-neural-networks-plot-mlp-alpha-py)
* [Derivative of sigmoid function](https://math.stackexchange.com/questions/78575/derivative-of-sigmoid-function-sigma-x-frac11e-x)
